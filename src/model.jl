module ML

using Random, Statistics
using LinearAlgebra, Flux, Zygote

import Base:
    length, reverse, iterate

export model, train!, validate, preprocess, update_dimension

# NOTE: all data is assumed to be dáµ¢ x N shaped here!
#       this is to allow for fast matrix multiplication through the network
#       it might be worthwhile to keep both memory layouts stored...

# ------------------------------------------------------------------------
# globals

Ïƒâ‚€(x)  = x + (sqrt(x^2 +1)-1)/2

# ------------------------------------------------------------------------
# types

# Iterator
"""
    struct LayerIterator
        width     :: Array{Int}
        dropout   :: Set{Int}
        normalize :: Set{Int}
        Ïƒáµ¢        :: Function
        Ïƒâ‚’        :: Function
        Ïƒ         :: Function
    end

An iterator used to generate dense latent layers within a neural network.
`width` denotes the widths of each layer; the length of this array immediately determines the depth.
`dropout` denotes the layers, as given by `width` that are followed by a dropout layer.
`normalize` denotes the layers, as given by `width` that are followed by a batch normalization layer.
`Ïƒáµ¢`, `Ïƒâ‚’`, `Ïƒ` is the activation energy on the first, last, and intermediate layers respectively.
"""
struct LayerIterator
    width     :: Array{Int}
    dropout   :: Set{Int}
    normalize :: Set{Int}
    Ïƒáµ¢        :: Function # activation on input layers
    Ïƒâ‚’        :: Function # activation on output layers
    Ïƒ         :: Function # activation on latent layers
end

length(it::LayerIterator)  = length(it.width) + length(it.dropout) + length(it.normalize)
reverse(it::LayerIterator) = LayerIterator(
                                reverse(it.width),
                                Set(length(it.width) - i - 1 for i in it.dropout),
                                Set(length(it.width) - i - 1 for i in it.normalize),
                                it.Ïƒáµ¢,
                                it.Ïƒáµ¢, # intentional -> want to make output = input
                                it.Ïƒ,
                             )

function iterate(it::LayerIterator)
    wâ‚ = it.width[1]
    wâ‚‚ = it.width[2]
    f  = Dense(wâ‚, wâ‚‚, it.Ïƒáµ¢)

    return f, (
        index     = 2,
        dropout   = 1 âˆˆ it.dropout,
        normalize = 1 âˆˆ it.normalize,
    )
end

function iterate(it::LayerIterator, state)
    return if state.dropout
               Dropout(0.5), (
                   index     = state.index,
                   dropout   = false,
                   normalize = state.normalize,
               )
           elseif state.normalize
               BatchNorm(it.width[state.index]), (
                   index     = state.index,
                   dropout   = false,
                   normalize = false,
               )
           elseif state.index < length(it.width)
                wâ‚ = it.width[state.index]
                wâ‚‚ = it.width[state.index+1]

                i  = state.index+1
                f  = Dense(wâ‚, wâ‚‚, i == length(it.width) ? it.Ïƒâ‚’ : it.Ïƒ)

                f, (
                     index     = i,
                     dropout   = (i-1) âˆˆ it.dropout,
                     normalize = (i-1) âˆˆ it.normalize,
                )
           else
               nothing
           end
end

# ------------------------------------------------------------------------
# functions

"""
    model(dáµ¢, dâ‚’; Ws=Int[], normalizes=Int[], dropouts=Int[], Ïƒ=elu)

Initialize an autoencoding neural network with input dimension `dáµ¢` and latent layers `dâ‚’`.
`Ws` specifies both the width and depth of the encoder layer - the width of each layer is given as an entry in the array while the length specifies the depth.
`normalizes` and `dropouts` denote which layers are followed by batch normalization and dropout specifically.
The decoder layer is given the mirror symmetric architecture.
"""
function model(dáµ¢, dâ‚’; Ws=Int[], normalizes=Int[], dropouts=Int[], Ïƒ=elu)
    # check for obvious errors here
    length(dropouts)   > 0 && length(Ws) < maximum(dropouts)   â‰¤ 0 && error("invalid dropout layer position")
    length(normalizes) > 0 && length(Ws) < maximum(normalizes) â‰¤ 0 && error("invalid normalization layer position")

    layers = LayerIterator(
                [dáµ¢; Ws; dâ‚’],
                Set(dropouts),
                Set(normalizes),
                Ïƒâ‚€, Ïƒâ‚€, Ïƒ
             )

    F   = Chain(layers...)
    FÂ¯Â¹ = Chain(reverse(layers)...)
    ğ•€   = Chain(F, FÂ¯Â¹)

    return (
        pullback=F,
        pushforward=FÂ¯Â¹,
        identity=ğ•€
    )
end

"""
    update_dimension(model, dâ‚’; Ïµ = 1e-6)

Add a colection of new neurons in the encoding layer to encode in the encoding layer to increase dimensions to `dâ‚’`.
Model weights for the initial dimensions are kept the same.
"""
function update_dimension(model, dâ‚’; Ïµ = 1e-6)
    F, FÂ¯Â¹, ğ•€ = model

    láµ¢ = F[end]
    lâ‚’ = FÂ¯Â¹[1]

    Wáµ¢, báµ¢ = Flux.params(láµ¢)
    Wâ‚’, bâ‚’ = Flux.params(lâ‚’)

    size(Wáµ¢,1) == dâ‚’ && return nothing
    size(Wáµ¢,1) >  dâ‚’ && error("can not reduce dimensionality of model") 

    Î´  = dâ‚’ - size(Wáµ¢, 1)

    WÌ„áµ¢ = vcat(Wáµ¢, Ïµ*randn(Î´, size(Wáµ¢,2)))
    bÌ„áµ¢ = vcat(báµ¢, Ïµ*randn(Î´))
    lÌ„áµ¢ = Dense(WÌ„áµ¢, bÌ„áµ¢, láµ¢.Ïƒ)

    WÌ„â‚’ = hcat(Wâ‚’, Ïµ*randn(size(Wâ‚’,1), Î´))
    bÌ„â‚’ = bâ‚’
    lÌ„â‚’ = Dense(WÌ„â‚’, bÌ„â‚’, lâ‚’.Ïƒ)

    F   = Chain( (i < length(F) ? f : lÌ„áµ¢ for (i,f) âˆˆ enumerate(F))...)
    FÂ¯Â¹ = Chain( (i > 1 ? f : lÌ„â‚’ for (i,f) âˆˆ enumerate(FÂ¯Â¹))...)
    ğ•€   = Chain(F, FÂ¯Â¹)

    return (
        pullback=F,
        pushforward=FÂ¯Â¹,
        identity=ğ•€
    )
end

# data batching
"""
    batch(data, n)

Randomly partition `data` into groups of size `n`.
"""
function batch(data, n)
    N = size(data,2)

    lo(i) = (i-1)*n + 1
    hi(i) = min((i)*n, N)

    Î¹ = randperm(N)

    return (data[:,Î¹[lo(i):hi(i)]] for i in 1:ceil(Int, N/n)), 
           (Î¹[lo(i):hi(i)] for i in 1:ceil(Int, N/n))
end


"""
    validate(data, len)

Reserve `len` samples from `data` during training process to allow for model validation.
"""
function validate(data, len)
    Î¹ = randperm(size(data,2))
    return (
        valid = data[:,Î¹[1:len]],
        train = data[:,Î¹[len+1:end]],
    ),(
        valid = Î¹[1:len],
        train = Î¹[len+1:end],
    )
end

function noop(epoch) end

# data training
"""
    train!(model, data, index, loss; B=64, Î·=1e-3, N=100, log=noop)

Trains autoencoder `model` on `data` by minimizing `loss`.
`index` stores the underlying indices of data used for training.
Will mutate the underlying parameters of `model`.
Optional parameters include:
  1. `B` denotes the batch size to be used.
  2. `N` denotes the number of epochs.
  3. `Î·` denotes the learning rate.
"""
function train!(model, data, index, loss; B=64, Î·=1e-3, N=100, log=noop)
    Î˜   = Flux.params(model.identity)
    opt = ADAM(Î·)

    for n âˆˆ 1:N
        X, I = batch(data, B)
        for (i,x) âˆˆ zip(I,X)
            E, backpropagate = pullback(Î˜) do
                loss(x, index[i], false)
            end

            isnan(E) && @goto done

            âˆ‡Î˜ = backpropagate(1f0)
            Flux.Optimise.update!(opt, Î˜, âˆ‡Î˜)
        end

        log(n)
    end
    @label done
end

# ------------------------------------------------------------------------
# tests

end
